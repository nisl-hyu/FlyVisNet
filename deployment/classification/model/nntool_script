#set debug true
#set input_transpose True

#set adjust_order True
#set input_width 324
#set input_height 244
#set_input_divisor 255
# imageformat input_1 rgb888 shift_int8
#adjust
# imageformat input_1 rgb888 offset_int8
# show
#aquant samples/* --scheme SQ8
# -T -H 61 -W 81 -f 8
#qshow
#fusions --scale8
#show
# qshow
# adjust
#qshow

# --- RUN INFERENCE ---
#set input_norm_func "x: x-128"
#dump samples/img1639561671.05393.jpeg -S float -P inference_result.npy
#dump samples/img1639561671.05393.jpeg -S quant -q -d -P inference_result_q.npy
#tensors -t float quant
#tensors -t float quant -Q
#qerror samples/* -T -H 120 -W 120
#save_state

set debug true
adjust
fusions --scale8
set input_norm_func "x:x/255"
aquant -f 8 samples/*
qshow
imageformat input_1 bw8 shift_int8
#set l3_ram_ext_managed true
#set default_input_exec_location "AT_MEM_L3_HRAM"
#set default_input_exec_location "AT_MEM_L2"
set graph_produce_node_names true
set graph_reorder_constant_in true
set graph_produce_operinfos true
set graph_monitor_cycles true
save_state

### Unconmment this if the model is already quantized ####
#set debug true
#adjust
#fusions --scale8
#show
#save_state
